{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart disease prediction\n",
    "This notebook will present some machine learning models to predict heart disease. The dataset used is the [Heart Failure Prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction) dataset from Kaggle.\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import stat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the file\n",
    "\n",
    "filename = 'data/heart.csv'\n",
    "\n",
    "print(f'File size: {stat(filename).st_size / 1024} kB.')\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(10))\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict the `HeartDisease` column, which is a binary column. We can see that the dataset is balanced, with 50% of the patients having heart disease and 50% not having heart disease.\n",
    "\n",
    "Let's first see the age repartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Age'], bins=df['Age'].nunique(), color='red', alpha=0.5, edgecolor='black', linewidth=1.2, density=True, label='Age')\n",
    "plt.title('Age distribution')\n",
    "plt.plot(np.linspace(min(df['Age']), max(df['Age']), 100), norm.pdf(np.linspace(min(df['Age']), max(df['Age']), 100), df['Age'].mean(), df['Age'].std()), color='blue', label='Mean')\n",
    "plt.xlabel('Age')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['RestingBP'], bins=df['RestingBP'].nunique(), color='red', alpha=0.5, edgecolor='black', linewidth=1.2, density=True, label='Age')\n",
    "plt.title('RestingPB distribution')\n",
    "plt.plot(np.linspace(min(df['RestingBP']), max(df['RestingBP']), 100), norm.pdf(np.linspace(min(df['RestingBP']), max(df['RestingBP']), 100), df['RestingBP'].mean(), df['RestingBP'].std()), color='blue', label='Mean')\n",
    "plt.xlabel('RestingPB')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Age'], df['HeartDisease'])\n",
    "plt.title('Heart Disease by Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Cholesterol'], df['HeartDisease'])\n",
    "plt.title('Heart Disease by Cholesterol level')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the correlation between the numerical features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.corr(numeric_only=True))\n",
    "plt.figure(figsize=(13,10))\n",
    "sns.heatmap(df.corr(), cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
    "plt.title('Correlation heatmap of the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "We have to preprocess the data before feeding it to the machine learning models.\n",
    "We will replace the categorical features with numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        dic = {}\n",
    "        i = 0\n",
    "        for k in df[col].unique():\n",
    "            dic[k] = i\n",
    "            i += 1\n",
    "        df[col] = df[col].map(dic)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the correlation between the numerical features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.corr(numeric_only=True))\n",
    "plt.figure(figsize=(13,10))\n",
    "sns.heatmap(df.corr(), cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
    "plt.title('Correlation heatmap of the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis shows that the `HeartDisease` column is correlated with the `Age` column, the `ChestPainType` column, the `ExerciseAngina` column,\n",
    "the `Oldpeak` column and the `ST_Slope` column.\n",
    "\n",
    "We also notice that these three last variables are correlated with each other.\n",
    "Also, as the `Oldpeak` column is correlated with the `ST_Slope` column, we will only keep the `ST_Slope` column, which is higher correlated with the target variable.\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "We are now going to use the `SelectKBest` class from `sklearn.feature_selection` to select the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X_new = SelectKBest(chi2, k=5).set_output(transform = \"pandas\").fit_transform(df.drop(['Oldpeak','HeartDisease'], axis=1), df['HeartDisease'])\n",
    "\n",
    "print(f'Original shape: {df.drop([\"Oldpeak\", \"HeartDisease\"], axis=1).shape}')\n",
    "print(f'New shape: {X_new.shape}')\n",
    "\n",
    "display(X_new.head(10))\n",
    "display(X_new.info())\n",
    "display(X_new.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the features have been selected, we are going to train our classifiers on the selected features.\n",
    "\n",
    "## Training the models\n",
    "### Spliiting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new, df['HeartDisease'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "#### Training the model\n",
    "We will start by training a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Accuracy: {reg.score(X_test, Y_test)}')\n",
    "\n",
    "scores = cross_val_score(reg, X_new, df['HeartDisease'], cv=5)\n",
    "print(f'Cross validation scores: {scores}')\n",
    "print(f'Cross validation mean score: {scores.mean()}')\n",
    "print(f'Cross validation standard deviation: {scores.std()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have a good accuracy, but we will try to improve it by tuning the hyperparameters.\n",
    "#### Tuning the hyperparameters\n",
    "As we made variable selection, wee will try to make a model that uses all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('HeartDisease', axis = 1), df['HeartDisease'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')\n",
    "\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Accuracy: {reg.score(X_test, Y_test)}')\n",
    "\n",
    "scores = cross_val_score(reg, df.drop('HeartDisease', axis = 1), df['HeartDisease'], cv=5)\n",
    "print(f'Cross validation scores: {scores}')\n",
    "print(f'Cross validation mean score: {scores.mean()}')\n",
    "print(f'Cross validation standard deviation: {scores.std()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have here a better result, with a better accuracy and a better recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(['HeartDisease', 'Oldpeak'], axis = 1), df['HeartDisease'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')\n",
    "\n",
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Accuracy: {reg.score(X_test, Y_test)}')\n",
    "\n",
    "scores = cross_val_score(reg, df.drop(['HeartDisease', 'Oldpeak'], axis = 1), df['HeartDisease'], cv=5)\n",
    "print(f'Cross validation scores: {scores}')\n",
    "print(f'Cross validation mean score: {scores.mean()}')\n",
    "print(f'Cross validation standard deviation: {scores.std()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the `Oldpeak` column was a good idea: scores are even higher, more than 0.8.\n",
    "\n",
    "But this model doesn't converge, so we will try another one.\n",
    "\n",
    "### Decision tree\n",
    "#### Training the model\n",
    "\n",
    "We will directly try it ont the global dataset, then try dropping the `Oldpeak` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('HeartDisease', axis = 1), df['HeartDisease'], test_size=0.2, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Accuracy: {tree.score(X_test, Y_test)}')\n",
    "\n",
    "scores = cross_val_score(tree, df.drop('HeartDisease', axis = 1), df['HeartDisease'], cv=5)\n",
    "print(f'Cross validation scores: {scores}')\n",
    "print(f'Cross validation mean score: {scores.mean()}')\n",
    "print(f'Cross validation standard deviation: {scores.std()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now drop the `Oldpeak` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(['HeartDisease', 'Oldpeak'], axis = 1), df['HeartDisease'], test_size=0.2, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Accuracy: {tree.score(X_test, Y_test)}')\n",
    "\n",
    "scores = cross_val_score(tree, df.drop(['HeartDisease', 'Oldpeak'], axis = 1), df['HeartDisease'], cv=5)\n",
    "print(f'Cross validation scores: {scores}')\n",
    "print(f'Cross validation mean score: {scores.mean()}')\n",
    "print(f'Cross validation standard deviation: {scores.std()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the tree model is less accurate than the logistic regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
