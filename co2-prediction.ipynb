{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C02 prediction\n",
    "This notebook introduces the predicition of CO2 concentration, using the available data on [Kaggle](https://www.kaggle.com/datasets/ulrikthygepedersen/co2-emissions-by-country).\n",
    "It will provide some prediction models for France and China.\n",
    "\n",
    "All models will be evaluated using the `score` method from [`scikit-learn`](https://scikit-learn.org/stable/), which will also provide the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the file\n",
    "\n",
    "file_stat = os.stat(\"data/co2_emissions_kt_by_country.csv\")\n",
    "print(f\"File size: {file_stat.st_size / 1024} kB.\")\n",
    "\n",
    "df = pd.read_csv(\"data/co2_emissions_kt_by_country.csv\")\n",
    "display(df.head(10))\n",
    "\n",
    "# Removing NA\n",
    "print(f\"Number of NA: {df.isna().sum().sum()}.\")\n",
    "if df.isna().sum().sum() > 0:\n",
    "    print(f\"Before removing NA: {df.shape}.\")\n",
    "    df.dropna(axis = 0)\n",
    "    print(f\"After removing NA: {df.shape}.\")\n",
    "else:\n",
    "    print(f\"Data frame shape: {df.shape}.\")\n",
    "\n",
    "print(f\"Number of countries: {df['country_code'].nunique()}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current dataframe holds data for 255 countries, each line is for a specific country during a specific year.\n",
    "We will first change this into a dictonnary, indexed by the country codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for k in df[\"country_code\"]:\n",
    "    df_dict[k] = df[df[\"country_code\"] == k].copy()\n",
    "    df_dict[k].drop(\"country_code\", axis = 1, inplace = True)\n",
    "\n",
    "print(f\"We have a set of {len(df_dict)} countries.\")\n",
    "print(\"The keys are the country codes.\\nNow, we have separated the data for each country.\")\n",
    "\n",
    "print(f\"The countries are:\")\n",
    "for k in df_dict:\n",
    "    print(f\"\\t{k} - {df_dict[k]['country_name'].iloc[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for a few countries, as example\n",
    "We are going to make a first plot of the evolution using the data for France and a few other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 9))\n",
    "plt.plot(df_dict[\"FRA\"][\"year\"],df_dict[\"FRA\"][\"value\"], label = \"France\")\n",
    "plt.plot(df_dict[\"USA\"][\"year\"],df_dict[\"USA\"][\"value\"], label = \"USA\")\n",
    "plt.plot(df_dict[\"CHN\"][\"year\"],df_dict[\"CHN\"][\"value\"], label = \"China\")\n",
    "plt.plot(df_dict[\"IND\"][\"year\"],df_dict[\"IND\"][\"value\"], label = \"India\")\n",
    "plt.plot(df_dict[\"RUS\"][\"year\"],df_dict[\"RUS\"][\"value\"], label = \"Russia\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the data is not linear, so we will use a polynomial regression to fit the data.\n",
    "However, unfortunately, for China, an exponential regression is more appropriate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for France\n",
    "### Linear regression\n",
    "Let's first try to train a linear model for France, even if the data are absolutely not linear.\n",
    "But first, we need a few information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"10 first lines of the data frame for France:\")\n",
    "display(df_dict[\"FRA\"].head(10))\n",
    "print(\"10 last lines of the data frame for France:\")\n",
    "display(df_dict[\"FRA\"].tail(10))\n",
    "print(\"Description of the data frame for France:\")\n",
    "df_dict[\"FRA\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can prepare the data for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models[\"FRA\"] = lin.LinearRegression()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_dict[\"FRA\"][\"year\"], df_dict[\"FRA\"][\"value\"], test_size = 0.2)\n",
    "X_train = X_train.values.reshape(-1, 1)\n",
    "Y_train = Y_train.values.reshape(-1, 1)\n",
    "X_test = X_test.values.reshape(-1, 1)\n",
    "Y_test = Y_test.values.reshape(-1, 1)\n",
    "\n",
    "models[\"FRA\"].fit(X_train, Y_train)\n",
    "prediction = models[\"FRA\"].predict(X_test)\n",
    "print(f\"Score for France: {models['FRA'].score(X_test, Y_test)}\")\n",
    "\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.plot(X_test, prediction, label = \"Prediction\")\n",
    "plt.scatter(X_test, Y_test, label = \"Real\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the data for France, we can see that the data is not linear, so we will use a polynomial regression. The scores confirms that.\n",
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(2,10)\n",
    "scores = []\n",
    "\n",
    "models_FRA = []\n",
    "\n",
    "for d in degrees:\n",
    "    poly = PolynomialFeatures(degree = d, include_bias = False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.fit_transform(X_test)\n",
    "    models_FRA.append(lin.LinearRegression())\n",
    "    models_FRA[d - 2].fit(X_train_poly, Y_train)\n",
    "    scores.append(models_FRA[d - 2].score(X_test_poly, Y_test))\n",
    "\n",
    "for d in degrees:\n",
    "    print(f\"Score for degree {d}: {scores[d - 2]}\")\n",
    "\n",
    "print(f\"Chosen degree: {2 + scores.index(max(scores))}\")\n",
    "models[\"FRA\"] = models_FRA[scores.index(max(scores))]\n",
    "\n",
    "poly = PolynomialFeatures(degree = 2 + scores.index(max(scores)), include_bias = False)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "prediction = models[\"FRA\"].predict(X_test_poly)\n",
    "\n",
    "prediction_list = []\n",
    "for i in range(len(X_test)):\n",
    "    prediction_list.append((X_test[i][0], prediction[i][0]))\n",
    "\n",
    "prediction_list.sort(key = lambda x: x[0])\n",
    "\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.scatter(X_test,Y_test, label = \"Real\")\n",
    "plt.plot([prediction_list[i][0] for i in range(len(prediction_list))], [prediction_list[i][1] for i in range(len(prediction_list))], label = \"Prediction\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a cross-validation of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cv = cross_val_score(models[\"FRA\"], X_test_poly, Y_test, cv = 5)\n",
    "print(f\"Scores from cross validation: {scores_cv}.\")\n",
    "print(f\"Mean score: {scores_cv.mean()}.\")\n",
    "print(f\"Scores standard deviation: {scores_cv.std()}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here notice that the best score is obtained with a degree of 3, but the score is still not very good.\n",
    "\n",
    "## Training for China\n",
    "As shown before, China has an exponential growth, so we will use an exponential regression.\n",
    "First, we need to prepare the data and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"10 first lines of the data frame for China:\")\n",
    "display(df_dict[\"CHN\"].head(10))\n",
    "print(\"10 last lines of the data frame for China:\")\n",
    "display(df_dict[\"CHN\"].tail(10))\n",
    "print(\"Description of the data frame for China:\")\n",
    "df_dict[\"CHN\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_dict[\"CHN\"][\"year\"], df_dict[\"CHN\"][\"value\"], test_size = 0.2)\n",
    "X_train = X_train.values.reshape(-1, 1)\n",
    "Y_train = np.log(Y_train.values).reshape(-1, 1)\n",
    "X_test = X_test.values.reshape(-1, 1)\n",
    "Y_test = np.log(Y_test.values).reshape(-1, 1)\n",
    "\n",
    "\n",
    "models[\"CHN\"] = lin.LinearRegression()\n",
    "\n",
    "models[\"CHN\"].fit(X_train, Y_train)\n",
    "prediction = models[\"CHN\"].predict(X_test)\n",
    "print(f\"Score for China: {models['CHN'].score(X_test, Y_test)}\")\n",
    "\n",
    "prediction_list = []\n",
    "for i in range(len(X_test)):\n",
    "    prediction_list.append((X_test[i][0], prediction[i][0]))\n",
    "\n",
    "prediction_list.sort(key = lambda x: x[0])\n",
    "\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.plot(np.array([prediction_list[i][0] for i in range(len(prediction_list))]).reshape(-1,1), np.exp(np.array([prediction_list[i][1] for i in range(len(prediction_list))])).reshape(-1,1), label = \"Prediction\")\n",
    "plt.scatter(X_test, np.exp(Y_test), label = \"Real\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is much better than the one for France.\n",
    "We'll now cross validate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cv = cross_val_score(models[\"CHN\"], X_test, Y_test, cv = 5)\n",
    "print(f\"Scores from cross validation: {scores_cv}.\")\n",
    "print(f\"Mean score: {scores_cv.mean()}.\")\n",
    "print(f\"Scores standard deviation: {scores_cv.std()}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the values computed for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = models[\"CHN\"].coef_[0][0]\n",
    "b = models[\"CHN\"].intercept_[0]\n",
    "print(f'The generated model is: value = {np.exp(b)} * ({np.exp(a)})^year.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
